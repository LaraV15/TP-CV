{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar MediaPipe para la detección de manos\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con Media Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x608 (no detections), 1451.5ms\n",
      "Speed: 17.0ms preprocess, 1451.5ms inference, 1.0ms postprocess per image at shape (1, 3, 800, 608)\n",
      "\n",
      "0: 736x800 (no detections), 1605.4ms\n",
      "Speed: 6.9ms preprocess, 1605.4ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 800x800 (no detections), 2018.3ms\n",
      "Speed: 7.2ms preprocess, 2018.3ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 800x800 (no detections), 2280.8ms\n",
      "Speed: 18.3ms preprocess, 2280.8ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1684.5ms\n",
      "Speed: 5.9ms preprocess, 1684.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Verifica si la cámara se ha abierto correctamente\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0  # Contador de cuadros procesados\n",
    "frame_delay = 10  # Espera de 10 ms entre cuadros (aproximadamente 100 FPS)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el cuadro de la cámara.\")\n",
    "        break\n",
    "\n",
    "    # Solo procesar cada 2 cuadros (por ejemplo, cada segundo cuadro)\n",
    "    frame_count += 1\n",
    "    if frame_count % 50 != 0:\n",
    "        cv2.imshow('Sign Language Detection', frame)\n",
    "        continue  # Saltar este cuadro y continuar con el siguiente\n",
    "    \n",
    "\n",
    "    # Convertir el cuadro de BGR a RGB para MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Procesar el cuadro con MediaPipe para detectar la mano\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # Si se detectan manos, extraemos la región de la mano\n",
    "    if results.multi_hand_landmarks:\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            # Obtener las coordenadas del centro de la mano (puedes usar diferentes puntos de los landmarks)\n",
    "            x_min = int(min([lm.x for lm in landmarks.landmark]) * frame.shape[1])\n",
    "            y_min = int(min([lm.y for lm in landmarks.landmark]) * frame.shape[0])\n",
    "            x_max = int(max([lm.x for lm in landmarks.landmark]) * frame.shape[1])\n",
    "            y_max = int(max([lm.y for lm in landmarks.landmark]) * frame.shape[0])\n",
    "\n",
    "            # Dibujar un rectángulo alrededor de la mano\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "            # Recortar la región de interés (la mano)\n",
    "            hand_roi = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            # Realizar la predicción de YOLO solo en la región de la mano\n",
    "            if hand_roi.size != 0:\n",
    "                results_yolo = model(hand_roi, conf=0.7)  # Umbral de confianza de 0.7\n",
    "\n",
    "                # Obtener los resultados (predicciones) y dibujarlos en el cuadro\n",
    "                for result in results_yolo[0].boxes.data:\n",
    "                    x1, y1, x2, y2 = result[:4].int().tolist()\n",
    "                    conf = result[4].item()\n",
    "                    class_id = int(result[5].item())\n",
    "                    class_name = results_yolo[0].names[class_id]\n",
    "\n",
    "                    # Dibujar la caja delimitadora sobre la imagen de la mano\n",
    "                    hand_roi = cv2.rectangle(hand_roi, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    hand_roi = cv2.putText(hand_roi, f'{class_name} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Colocar la región de la mano procesada en la imagen original\n",
    "            frame[y_min:y_max, x_min:x_max] = hand_roi\n",
    "\n",
    "    # Mostrar el cuadro con OpenCV\n",
    "    cv2.imshow('Sign Language Detection', frame)\n",
    "\n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(frame_delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cerrar la cámara y las ventanas de OpenCV\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin Media Pipe para el modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo YOLOv8 y optimizar\n",
    "model = YOLO('best_1.pt')\n",
    "model.fp16 = True  # Habilitar inferencia en FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 (no detections), 3018.2ms\n",
      "Speed: 164.2ms preprocess, 3018.2ms inference, 31.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1462.8ms\n",
      "Speed: 7.8ms preprocess, 1462.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1424.6ms\n",
      "Speed: 10.9ms preprocess, 1424.6ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1602.0ms\n",
      "Speed: 7.6ms preprocess, 1602.0ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1625.8ms\n",
      "Speed: 8.0ms preprocess, 1625.8ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1556.1ms\n",
      "Speed: 12.7ms preprocess, 1556.1ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1552.1ms\n",
      "Speed: 8.6ms preprocess, 1552.1ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1530.2ms\n",
      "Speed: 8.9ms preprocess, 1530.2ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 C, 1513.0ms\n",
      "Speed: 7.5ms preprocess, 1513.0ms inference, 19.2ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1577.8ms\n",
      "Speed: 8.0ms preprocess, 1577.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 V, 1595.8ms\n",
      "Speed: 7.2ms preprocess, 1595.8ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 V, 1580.3ms\n",
      "Speed: 9.8ms preprocess, 1580.3ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 V, 1596.8ms\n",
      "Speed: 8.5ms preprocess, 1596.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1517.0ms\n",
      "Speed: 10.1ms preprocess, 1517.0ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1566.6ms\n",
      "Speed: 23.3ms preprocess, 1566.6ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1515.7ms\n",
      "Speed: 9.0ms preprocess, 1515.7ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1531.7ms\n",
      "Speed: 12.4ms preprocess, 1531.7ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1573.5ms\n",
      "Speed: 9.0ms preprocess, 1573.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1525.4ms\n",
      "Speed: 7.5ms preprocess, 1525.4ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1506.6ms\n",
      "Speed: 8.5ms preprocess, 1506.6ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1553.6ms\n",
      "Speed: 18.4ms preprocess, 1553.6ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1501.6ms\n",
      "Speed: 7.5ms preprocess, 1501.6ms inference, 3.6ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1463.8ms\n",
      "Speed: 5.5ms preprocess, 1463.8ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1564.0ms\n",
      "Speed: 7.4ms preprocess, 1564.0ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "# Configurar la cámara para menor resolución\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Reducir resolución\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)  # Limitar FPS\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "last_process_time = time.time()\n",
    "process_interval = 0.5  # Procesar 2 frames por segundo (1/2 = 0.5 segundos)\n",
    "\n",
    "# Crear ventana una sola vez\n",
    "cv2.namedWindow('Sign Language Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el cuadro de la cámara.\")\n",
    "        break\n",
    "    \n",
    "    # Redimensionar el frame para procesamiento más rápido\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Procesar frame cada 0.5 segundos (2 FPS para el procesamiento)\n",
    "    if current_time - last_process_time >= process_interval:\n",
    "        # Procesar frame con YOLO\n",
    "        results_yolo = model(frame, conf=0.5)\n",
    "        \n",
    "        for result in results_yolo[0].boxes.data:\n",
    "            x1, y1, x2, y2 = map(int, result[:4])\n",
    "            conf = float(result[4])\n",
    "            class_id = int(result[5])\n",
    "            class_name = results_yolo[0].names[class_id]\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{class_name} {conf:.2f}', \n",
    "                      (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.6, (0, 255, 0), 1)\n",
    "        \n",
    "        last_process_time = current_time\n",
    "    \n",
    "    # Mostrar el frame en tiempo real (30 FPS)\n",
    "    cv2.imshow('Sign Language Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin Media Pipe para el modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo YOLOv8 y optimizar\n",
    "model = YOLO('best_2.pt')\n",
    "model.fp16 = True  # Habilitar inferencia en FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 (no detections), 2098.6ms\n",
      "Speed: 35.7ms preprocess, 2098.6ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 968.2ms\n",
      "Speed: 22.5ms preprocess, 968.2ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 E, 908.8ms\n",
      "Speed: 8.5ms preprocess, 908.8ms inference, 6.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 873.5ms\n",
      "Speed: 10.5ms preprocess, 873.5ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 926.5ms\n",
      "Speed: 15.5ms preprocess, 926.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 944.1ms\n",
      "Speed: 10.5ms preprocess, 944.1ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 904.2ms\n",
      "Speed: 10.5ms preprocess, 904.2ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 896.5ms\n",
      "Speed: 13.0ms preprocess, 896.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 915.5ms\n",
      "Speed: 8.8ms preprocess, 915.5ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 887.2ms\n",
      "Speed: 10.5ms preprocess, 887.2ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 943.1ms\n",
      "Speed: 11.5ms preprocess, 943.1ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 981.0ms\n",
      "Speed: 6.5ms preprocess, 981.0ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 894.8ms\n",
      "Speed: 19.6ms preprocess, 894.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 E, 960.3ms\n",
      "Speed: 8.0ms preprocess, 960.3ms inference, 0.8ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 947.8ms\n",
      "Speed: 20.2ms preprocess, 947.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 905.2ms\n",
      "Speed: 6.0ms preprocess, 905.2ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 931.9ms\n",
      "Speed: 8.5ms preprocess, 931.9ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 N, 986.3ms\n",
      "Speed: 20.5ms preprocess, 986.3ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 926.8ms\n",
      "Speed: 20.4ms preprocess, 926.8ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 876.5ms\n",
      "Speed: 12.7ms preprocess, 876.5ms inference, 0.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 926.8ms\n",
      "Speed: 7.1ms preprocess, 926.8ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 938.2ms\n",
      "Speed: 10.4ms preprocess, 938.2ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 953.2ms\n",
      "Speed: 22.8ms preprocess, 953.2ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 918.3ms\n",
      "Speed: 9.4ms preprocess, 918.3ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 879.6ms\n",
      "Speed: 9.1ms preprocess, 879.6ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 908.3ms\n",
      "Speed: 18.4ms preprocess, 908.3ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 924.7ms\n",
      "Speed: 13.7ms preprocess, 924.7ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 894.9ms\n",
      "Speed: 13.7ms preprocess, 894.9ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 936.0ms\n",
      "Speed: 9.7ms preprocess, 936.0ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 858.5ms\n",
      "Speed: 9.0ms preprocess, 858.5ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 988.4ms\n",
      "Speed: 9.5ms preprocess, 988.4ms inference, 3.2ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 908.9ms\n",
      "Speed: 7.0ms preprocess, 908.9ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 955.9ms\n",
      "Speed: 9.2ms preprocess, 955.9ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 928.5ms\n",
      "Speed: 8.0ms preprocess, 928.5ms inference, 16.2ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 916.1ms\n",
      "Speed: 7.7ms preprocess, 916.1ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 894.4ms\n",
      "Speed: 9.2ms preprocess, 894.4ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 850.2ms\n",
      "Speed: 10.7ms preprocess, 850.2ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 831.8ms\n",
      "Speed: 5.5ms preprocess, 831.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 867.6ms\n",
      "Speed: 11.2ms preprocess, 867.6ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 843.6ms\n",
      "Speed: 8.7ms preprocess, 843.6ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 849.0ms\n",
      "Speed: 7.5ms preprocess, 849.0ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "# Configurar la cámara para menor resolución\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Reducir resolución\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)  # Limitar FPS\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "last_process_time = time.time()\n",
    "process_interval = 0.5  # Procesar 2 frames por segundo (1/2 = 0.5 segundos)\n",
    "\n",
    "# Crear ventana una sola vez\n",
    "cv2.namedWindow('Sign Language Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el cuadro de la cámara.\")\n",
    "        break\n",
    "    \n",
    "    # Redimensionar el frame para procesamiento más rápido\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Procesar frame cada 0.5 segundos (2 FPS para el procesamiento)\n",
    "    if current_time - last_process_time >= process_interval:\n",
    "        # Procesar frame con YOLO\n",
    "        results_yolo = model(frame, conf=0.5)\n",
    "        \n",
    "        for result in results_yolo[0].boxes.data:\n",
    "            x1, y1, x2, y2 = map(int, result[:4])\n",
    "            conf = float(result[4])\n",
    "            class_id = int(result[5])\n",
    "            class_name = results_yolo[0].names[class_id]\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{class_name} {conf:.2f}', \n",
    "                      (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.6, (0, 255, 0), 1)\n",
    "        \n",
    "        last_process_time = current_time\n",
    "    \n",
    "    # Mostrar el frame en tiempo real (30 FPS)\n",
    "    cv2.imshow('Sign Language Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
