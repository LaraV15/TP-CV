{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar MediaPipe para la detección de manos\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con Media Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x608 (no detections), 1451.5ms\n",
      "Speed: 17.0ms preprocess, 1451.5ms inference, 1.0ms postprocess per image at shape (1, 3, 800, 608)\n",
      "\n",
      "0: 736x800 (no detections), 1605.4ms\n",
      "Speed: 6.9ms preprocess, 1605.4ms inference, 1.0ms postprocess per image at shape (1, 3, 736, 800)\n",
      "\n",
      "0: 800x800 (no detections), 2018.3ms\n",
      "Speed: 7.2ms preprocess, 2018.3ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 800x800 (no detections), 2280.8ms\n",
      "Speed: 18.3ms preprocess, 2280.8ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1684.5ms\n",
      "Speed: 5.9ms preprocess, 1684.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Verifica si la cámara se ha abierto correctamente\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "frame_count = 0  # Contador de cuadros procesados\n",
    "frame_delay = 10  # Espera de 10 ms entre cuadros (aproximadamente 100 FPS)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el cuadro de la cámara.\")\n",
    "        break\n",
    "\n",
    "    # Solo procesar cada 2 cuadros (por ejemplo, cada segundo cuadro)\n",
    "    frame_count += 1\n",
    "    if frame_count % 50 != 0:\n",
    "        cv2.imshow('Sign Language Detection', frame)\n",
    "        continue  # Saltar este cuadro y continuar con el siguiente\n",
    "    \n",
    "\n",
    "    # Convertir el cuadro de BGR a RGB para MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Procesar el cuadro con MediaPipe para detectar la mano\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # Si se detectan manos, extraemos la región de la mano\n",
    "    if results.multi_hand_landmarks:\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            # Obtener las coordenadas del centro de la mano (puedes usar diferentes puntos de los landmarks)\n",
    "            x_min = int(min([lm.x for lm in landmarks.landmark]) * frame.shape[1])\n",
    "            y_min = int(min([lm.y for lm in landmarks.landmark]) * frame.shape[0])\n",
    "            x_max = int(max([lm.x for lm in landmarks.landmark]) * frame.shape[1])\n",
    "            y_max = int(max([lm.y for lm in landmarks.landmark]) * frame.shape[0])\n",
    "\n",
    "            # Dibujar un rectángulo alrededor de la mano\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "            # Recortar la región de interés (la mano)\n",
    "            hand_roi = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            # Realizar la predicción de YOLO solo en la región de la mano\n",
    "            if hand_roi.size != 0:\n",
    "                results_yolo = model(hand_roi, conf=0.7)  # Umbral de confianza de 0.7\n",
    "\n",
    "                # Obtener los resultados (predicciones) y dibujarlos en el cuadro\n",
    "                for result in results_yolo[0].boxes.data:\n",
    "                    x1, y1, x2, y2 = result[:4].int().tolist()\n",
    "                    conf = result[4].item()\n",
    "                    class_id = int(result[5].item())\n",
    "                    class_name = results_yolo[0].names[class_id]\n",
    "\n",
    "                    # Dibujar la caja delimitadora sobre la imagen de la mano\n",
    "                    hand_roi = cv2.rectangle(hand_roi, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    hand_roi = cv2.putText(hand_roi, f'{class_name} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Colocar la región de la mano procesada en la imagen original\n",
    "            frame[y_min:y_max, x_min:x_max] = hand_roi\n",
    "\n",
    "    # Mostrar el cuadro con OpenCV\n",
    "    cv2.imshow('Sign Language Detection', frame)\n",
    "\n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(frame_delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cerrar la cámara y las ventanas de OpenCV\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin Media Pipe para el modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo YOLOv8 y optimizar\n",
    "model = YOLO('best_1.pt')\n",
    "model.fp16 = True  # Habilitar inferencia en FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 (no detections), 3018.2ms\n",
      "Speed: 164.2ms preprocess, 3018.2ms inference, 31.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1462.8ms\n",
      "Speed: 7.8ms preprocess, 1462.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1424.6ms\n",
      "Speed: 10.9ms preprocess, 1424.6ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1602.0ms\n",
      "Speed: 7.6ms preprocess, 1602.0ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1625.8ms\n",
      "Speed: 8.0ms preprocess, 1625.8ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1556.1ms\n",
      "Speed: 12.7ms preprocess, 1556.1ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1552.1ms\n",
      "Speed: 8.6ms preprocess, 1552.1ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1530.2ms\n",
      "Speed: 8.9ms preprocess, 1530.2ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 C, 1513.0ms\n",
      "Speed: 7.5ms preprocess, 1513.0ms inference, 19.2ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1577.8ms\n",
      "Speed: 8.0ms preprocess, 1577.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 V, 1595.8ms\n",
      "Speed: 7.2ms preprocess, 1595.8ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 V, 1580.3ms\n",
      "Speed: 9.8ms preprocess, 1580.3ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 V, 1596.8ms\n",
      "Speed: 8.5ms preprocess, 1596.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1517.0ms\n",
      "Speed: 10.1ms preprocess, 1517.0ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1566.6ms\n",
      "Speed: 23.3ms preprocess, 1566.6ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1515.7ms\n",
      "Speed: 9.0ms preprocess, 1515.7ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1531.7ms\n",
      "Speed: 12.4ms preprocess, 1531.7ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1573.5ms\n",
      "Speed: 9.0ms preprocess, 1573.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1525.4ms\n",
      "Speed: 7.5ms preprocess, 1525.4ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1506.6ms\n",
      "Speed: 8.5ms preprocess, 1506.6ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1553.6ms\n",
      "Speed: 18.4ms preprocess, 1553.6ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1501.6ms\n",
      "Speed: 7.5ms preprocess, 1501.6ms inference, 3.6ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 L, 1463.8ms\n",
      "Speed: 5.5ms preprocess, 1463.8ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 1564.0ms\n",
      "Speed: 7.4ms preprocess, 1564.0ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "# Configurar la cámara para menor resolución\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Reducir resolución\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)  # Limitar FPS\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "last_process_time = time.time()\n",
    "process_interval = 0.5  # Procesar 2 frames por segundo (1/2 = 0.5 segundos)\n",
    "\n",
    "# Crear ventana una sola vez\n",
    "cv2.namedWindow('Sign Language Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el cuadro de la cámara.\")\n",
    "        break\n",
    "    \n",
    "    # Redimensionar el frame para procesamiento más rápido\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Procesar frame cada 0.5 segundos (2 FPS para el procesamiento)\n",
    "    if current_time - last_process_time >= process_interval:\n",
    "        # Procesar frame con YOLO\n",
    "        results_yolo = model(frame, conf=0.5)\n",
    "        \n",
    "        for result in results_yolo[0].boxes.data:\n",
    "            x1, y1, x2, y2 = map(int, result[:4])\n",
    "            conf = float(result[4])\n",
    "            class_id = int(result[5])\n",
    "            class_name = results_yolo[0].names[class_id]\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{class_name} {conf:.2f}', \n",
    "                      (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.6, (0, 255, 0), 1)\n",
    "        \n",
    "        last_process_time = current_time\n",
    "    \n",
    "    # Mostrar el frame en tiempo real (30 FPS)\n",
    "    cv2.imshow('Sign Language Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin Media Pipe para el modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo YOLOv8 y optimizar\n",
    "model = YOLO('best_3.pt')\n",
    "model.fp16 = True  # Habilitar inferencia en FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 (no detections), 562.2ms\n",
      "Speed: 26.7ms preprocess, 562.2ms inference, 7.6ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 318.1ms\n",
      "Speed: 10.1ms preprocess, 318.1ms inference, 3.7ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 323.4ms\n",
      "Speed: 5.4ms preprocess, 323.4ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 307.8ms\n",
      "Speed: 0.0ms preprocess, 307.8ms inference, 6.3ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 291.5ms\n",
      "Speed: 4.3ms preprocess, 291.5ms inference, 14.8ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 261.9ms\n",
      "Speed: 0.0ms preprocess, 261.9ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 283.0ms\n",
      "Speed: 0.0ms preprocess, 283.0ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 241.6ms\n",
      "Speed: 0.0ms preprocess, 241.6ms inference, 14.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 269.2ms\n",
      "Speed: 0.0ms preprocess, 269.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 257.1ms\n",
      "Speed: 0.0ms preprocess, 257.1ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 243.9ms\n",
      "Speed: 0.0ms preprocess, 243.9ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 259.7ms\n",
      "Speed: 0.0ms preprocess, 259.7ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 243.5ms\n",
      "Speed: 0.0ms preprocess, 243.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 258.0ms\n",
      "Speed: 0.0ms preprocess, 258.0ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 240.6ms\n",
      "Speed: 0.0ms preprocess, 240.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 242.7ms\n",
      "Speed: 7.8ms preprocess, 242.7ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 248.6ms\n",
      "Speed: 0.0ms preprocess, 248.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 263.2ms\n",
      "Speed: 0.0ms preprocess, 263.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 238.4ms\n",
      "Speed: 0.0ms preprocess, 238.4ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 240.0ms\n",
      "Speed: 11.3ms preprocess, 240.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 237.5ms\n",
      "Speed: 5.7ms preprocess, 237.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 237.1ms\n",
      "Speed: 5.5ms preprocess, 237.1ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 268.0ms\n",
      "Speed: 0.0ms preprocess, 268.0ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 260.5ms\n",
      "Speed: 4.6ms preprocess, 260.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 241.5ms\n",
      "Speed: 9.6ms preprocess, 241.5ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 233.6ms\n",
      "Speed: 13.0ms preprocess, 233.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 272.6ms\n",
      "Speed: 1.0ms preprocess, 272.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 216.7ms\n",
      "Speed: 8.8ms preprocess, 216.7ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 251.5ms\n",
      "Speed: 11.3ms preprocess, 251.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 K, 233.6ms\n",
      "Speed: 0.0ms preprocess, 233.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 267.6ms\n",
      "Speed: 7.9ms preprocess, 267.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 230.0ms\n",
      "Speed: 0.0ms preprocess, 230.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 247.5ms\n",
      "Speed: 1.2ms preprocess, 247.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 251.8ms\n",
      "Speed: 8.3ms preprocess, 251.8ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 279.2ms\n",
      "Speed: 4.2ms preprocess, 279.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 234.6ms\n",
      "Speed: 0.0ms preprocess, 234.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 226.5ms\n",
      "Speed: 5.4ms preprocess, 226.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 234.8ms\n",
      "Speed: 10.6ms preprocess, 234.8ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 238.9ms\n",
      "Speed: 0.0ms preprocess, 238.9ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 284.8ms\n",
      "Speed: 5.5ms preprocess, 284.8ms inference, 0.5ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 239.3ms\n",
      "Speed: 0.0ms preprocess, 239.3ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 A, 230.2ms\n",
      "Speed: 4.7ms preprocess, 230.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 257.7ms\n",
      "Speed: 5.1ms preprocess, 257.7ms inference, 0.8ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 266.1ms\n",
      "Speed: 10.4ms preprocess, 266.1ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 283.2ms\n",
      "Speed: 0.0ms preprocess, 283.2ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 277.2ms\n",
      "Speed: 0.0ms preprocess, 277.2ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 296.6ms\n",
      "Speed: 0.0ms preprocess, 296.6ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 258.0ms\n",
      "Speed: 6.2ms preprocess, 258.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 254.7ms\n",
      "Speed: 4.6ms preprocess, 254.7ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 277.0ms\n",
      "Speed: 11.9ms preprocess, 277.0ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 246.4ms\n",
      "Speed: 0.0ms preprocess, 246.4ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "# Configurar la cámara para menor resolución\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Reducir resolución\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)  # Limitar FPS\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "last_process_time = time.time()\n",
    "process_interval = 0.5  # Procesar 2 frames por segundo (1/2 = 0.5 segundos)\n",
    "\n",
    "# Crear ventana una sola vez\n",
    "cv2.namedWindow('Sign Language Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el cuadro de la cámara.\")\n",
    "        break\n",
    "    \n",
    "    # Redimensionar el frame para procesamiento más rápido\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Procesar frame cada 0.5 segundos (2 FPS para el procesamiento)\n",
    "    if current_time - last_process_time >= process_interval:\n",
    "        # Procesar frame con YOLO\n",
    "        results_yolo = model(frame, conf=0.5)\n",
    "        \n",
    "        for result in results_yolo[0].boxes.data:\n",
    "            x1, y1, x2, y2 = map(int, result[:4])\n",
    "            conf = float(result[4])\n",
    "            class_id = int(result[5])\n",
    "            class_name = results_yolo[0].names[class_id]\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{class_name} {conf:.2f}', \n",
    "                      (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                      0.6, (0, 255, 0), 1)\n",
    "        \n",
    "        last_process_time = current_time\n",
    "    \n",
    "    # Mostrar el frame en tiempo real (30 FPS)\n",
    "    cv2.imshow('Sign Language Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
